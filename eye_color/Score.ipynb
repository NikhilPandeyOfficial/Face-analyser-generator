{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_col_1_header=\"path\"\n",
    "csv_col_2_header=\"eye_color\"\n",
    "path_to_val_img=\"./val_img/\"\n",
    "with open('dataset.csv','w',newline='') as new_file:\n",
    "    csv_writer=csv.writer(new_file)\n",
    "    csv_writer.writerow([csv_col_1_header,csv_col_2_header])\n",
    "    \n",
    "    # 'folders' variable lists the folders\n",
    "    # later the index of the folder name in 'folders' variable\n",
    "    # is used to write the lable of the image\n",
    "    # eg. if folders[1] has value \"Black\" then in the csv for Hair-Color\n",
    "    # the hair_color value will be 1\n",
    "    \n",
    "    # if the indices of the folders do not match the 'digital2label' variable\n",
    "    # in the training file then manually pass the list in 'folders' variable\n",
    "    # eg.\n",
    "    folders={0:\"blue\",1:\"brown\",2:\"green\"}\n",
    "    # folders=os.listdir(path_to_val_img)\n",
    "    \n",
    "    for i in range(0,len(folders)):\n",
    "        files=os.listdir(path_to_val_img+folders[i]+\"/\")\n",
    "        for file in files:\n",
    "            write_this=[path_to_val_img+folders[i]+\"/\"+file,i]\n",
    "            csv_writer.writerow(write_this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(X_train):\n",
    "    X_data =[]\n",
    "    count = 0\n",
    "    last_face = None\n",
    "    for file in tqdm(X_train['path']):\n",
    "        face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        try:\n",
    "            face =cv2.resize(face, (300,300)) # dimensions (height, width) in witch the model was trained\n",
    "        except Exception as e:\n",
    "            count+=1\n",
    "            X_data.append(last_face)\n",
    "            continue\n",
    "        last_face = face\n",
    "        face = np.asarray(face)\n",
    "        face = face.astype('float32')\n",
    "        face /= 255\n",
    "        X_data.append(face)\n",
    "    print('skipped rows ', count)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the X_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2510/2510 [01:57<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped rows  18\n",
      "Shape of Dataset:: eye_color (2510, 300, 300, 3) (2510, 3)\n"
     ]
    }
   ],
   "source": [
    "file_path=\"./dataset.csv\"\n",
    "x_columns_for_remove=\"eye_color\" # change according to the label column header in Dataset.csv \n",
    "y_columns_for_remove=\"path\" # no need to change\n",
    "training_feature = 'eye_color'\n",
    "\n",
    "dataset = pd.read_csv(file_path)\n",
    "X_test = dataset.drop(columns=x_columns_for_remove)\n",
    "y_test = dataset.drop(columns=y_columns_for_remove)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "X_test = get_data_from_local(X_test)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "print('Shape of Dataset::',training_feature,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_model = 'final_cnn_model_checkpoint.tf' # model checkpoint filename\n",
    "model = load_model(path_of_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 171s 2s/step - loss: 26.3936 - accuracy: 0.4685\n",
      "Baseline Error: 53.15%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
