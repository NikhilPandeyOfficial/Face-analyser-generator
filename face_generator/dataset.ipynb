{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nikhil\\\\Downloads\\\\archive\\\\img_align_celeba\\\\img_align_celeba\\\\\"\n",
    "images = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(35001, 70001):\n",
    "    image = imageio.imread(path+images[i])\n",
    "    imageio.imwrite(\"./images/\"+images[i], image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(file, l, b):\n",
    "    face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face =cv2.resize(face, (l, b))\n",
    "    face = np.asarray(face)\n",
    "    face = face.astype('float32')\n",
    "    face /= 255\n",
    "    return np.array(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"images/\"\n",
    "real_images_path = []\n",
    "# for path in os.listdir(d):\n",
    "#     full_path = os.path.join(d, path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         real_images_path.append(str(full_path))\n",
    "for i in range(35001, 70002):\n",
    "    full_path = os.path.join(d, \"0\" + str(i) + \".jpg\")\n",
    "    if os.path.isfile(full_path):\n",
    "        real_images_path.append(str(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000168C3FF8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000168C4204E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'age':[],\n",
    "    'gender':[],\n",
    "    'race':[],\n",
    "    'eye_color':[],\n",
    "    'hair_color':[],\n",
    "    'beard': [],\n",
    "    'face_color':[],\n",
    "    'image':[]\n",
    "}\n",
    "age_model = load_model('model/age_model_checkpoint.tf')\n",
    "gender_model = load_model('model/gender_model_checkpoint.tf')\n",
    "race_model = load_model('model/race_model_checkpoint.tf')\n",
    "eye_color_model = load_model('model/eye_color_model_checkpoint.tf')\n",
    "hair_color_model = load_model('model/hair_color_model_checkpoint.tf')\n",
    "beard_model = load_model('model/beard_model_checkpoint.tf')\n",
    "\n",
    "for image in real_images_path:\n",
    "    temp = image\n",
    "    image_AGR = get_data_from_local(image, 200, 200)\n",
    "    image_AGR = np.expand_dims(image_AGR, axis=0)\n",
    "    \n",
    "    image_eye_color = get_data_from_local(image, 300, 300)\n",
    "    image_eye_color = np.expand_dims(image_eye_color, axis=0)\n",
    "    \n",
    "    image_hCB = get_data_from_local(image, 178, 218)\n",
    "    image_hCB = np.expand_dims(image_hCB, axis=0)\n",
    "    \n",
    "    data['age'].append(age_model.predict(image_AGR).argmax())\n",
    "    data['gender'].append(gender_model.predict(image_AGR).argmax())\n",
    "    data['race'].append(race_model.predict(image_AGR).argmax())\n",
    "    data['eye_color'].append(eye_color_model.predict(image_eye_color).argmax())\n",
    "    data['hair_color'].append(hair_color_model.predict(image_hCB).argmax())\n",
    "    data['beard'].append(beard_model.predict(image_hCB).argmax())\n",
    "    data['image'].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data,columns=['age','gender','race','eye_color','hair_color','beard','image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('main_dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
