{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataset_(\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    start_row,\n",
    "    ):\n",
    "    df = pd.read_csv(file_path)[start_row:start_row+image_per_batch]\n",
    "    \n",
    "    df = df.drop('Unnamed: 0',axis=1)\n",
    "    \n",
    "    y = get_data_from_local(df)\n",
    "    x = df.drop('image',axis=1)\n",
    "    x = x.values\n",
    "    \n",
    "    return x , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(X_train):\n",
    "    X_data =[]\n",
    "    for file in tqdm(X_train['image']):\n",
    "        face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face =cv2.resize(face, (200,200))\n",
    "#         face = np.expand_dims(face, axis=2)\n",
    "        face = np.asarray(face)\n",
    "        face = face.astype('float32')\n",
    "        face /= 255\n",
    "        X_data.append(face)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D , MaxPool2D ,ZeroPadding2D , UpSampling2D ,Reshape, Input ,Dense, Activation,Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "\n",
    "def model(number_of_label):\n",
    "    inp = Input(shape = (number_of_label,))\n",
    "    \n",
    "    fc1 = Dense(500,activation=\"sigmoid\")(inp)\n",
    "    \n",
    "    fc2 = Dense(2000,activation=\"sigmoid\")(fc1)\n",
    "    \n",
    "    fc3 = Dense(4000,activation=\"sigmoid\")(fc2)\n",
    "\n",
    "    fc4 = Dense(8836,activation=\"sigmoid\")(fc3)\n",
    "\n",
    "    res1 = Reshape((47,47,4))(fc4)\n",
    "    zrp1 = ZeroPadding2D((1,1))(res1)\n",
    "\n",
    "    conv4 = Conv2D(16,(3,3),padding=\"same\" , activation =\"relu\")(zrp1)\n",
    "    ups1 = UpSampling2D((2,2))(conv4)\n",
    "    \n",
    "    conv8 = Conv2D(16,(3,3),padding=\"same\" , activation =\"relu\")(ups1)\n",
    "    ups7 = UpSampling2D((2,2))(conv8)\n",
    "\n",
    "    zrp2 = ZeroPadding2D((1,1))(ups7)\n",
    "    conv5 = Conv2D(32,(3,3),padding=\"same\" , activation =\"relu\")(zrp2)\n",
    "\n",
    "    zrp3 = ZeroPadding2D((1,1))(conv5)\n",
    "    conv6 = Conv2D(3,(3,3),padding=\"same\" , activation=\"relu\")(zrp3)\n",
    "    c_a_e = Model(inputs=inp, outputs=conv6)\n",
    "    c_a_e.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    c_a_e.summary()\n",
    "    return c_a_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "    start_row,\n",
    "    number_of_labels,\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    max_limit,\n",
    "    path_of_model\n",
    "):\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=path_of_model,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_format='tf',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             verbose=1\n",
    "                            )\n",
    "    early_stopping_monitor = EarlyStopping(patience=2,verbose=1) \n",
    "    \n",
    "    for x in range(start_row,max_limit,image_per_batch):\n",
    "        \n",
    "        print()\n",
    "        print('**********{} -- {} out of {}************'.format(x,x+image_per_batch,max_limit))\n",
    "        print()\n",
    "    \n",
    "        X_train , y_train   =   training_dataset_(\n",
    "                        file_path = file_path,\n",
    "                        start_row = x,\n",
    "                        image_per_batch = image_per_batch,\n",
    "        )\n",
    "        \n",
    "#         if x != 0:\n",
    "        final_cnn = load_model(path_of_model)\n",
    "#         else:\n",
    "#             final_cnn = model(number_of_labels)\n",
    "            \n",
    "        try:\n",
    "            final_cnn_history = final_cnn.fit(x=X_train,\n",
    "                                          y=y_train,\n",
    "                                          batch_size=64,\n",
    "                                          validation_split=0.5,\n",
    "                                          epochs=15,\n",
    "                                          callbacks=[checkpoint,early_stopping_monitor],\n",
    "                                          shuffle=False    # shuffle=False to reduce randomness and increase reproducibility\n",
    "                                         )\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(\n",
    "    start_row = 16000,\n",
    "    number_of_labels = 6,\n",
    "    file_path = 'main_dataset1.csv',\n",
    "    image_per_batch = 1000,\n",
    "    max_limit = 35000,\n",
    "    path_of_model = 'final_cnn_checkpoint.tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def drawimage(image,title=\"facial feature\"):\n",
    "    image = image.reshape(100,100,3)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title,fontsize=20)\n",
    "    plt.show()\n",
    "model = load_model('./final_cnn_checkpoint.tf')\n",
    "inp = np.array([1,1,1,1,1,1])\n",
    "inp = np.expand_dims(inp,axis=0)\n",
    "pred = model.predict(inp)\n",
    "print(pred.shape)\n",
    "drawimage(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
